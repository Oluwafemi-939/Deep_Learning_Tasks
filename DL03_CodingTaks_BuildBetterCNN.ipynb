{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "wo_EghI4aAXJ"
   },
   "source": [
    "# Homework 2, *part 2*\n",
    "### (60 points total)\n",
    "\n",
    "In this part, you will build a convolutional neural network (CNN) to solve (yet another) image classification problem: the Tiny ImageNet dataset (200 classes, 100K training images, 10K validation images). Try to achieve as high accuracy as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9LpyS7nAaAXO"
   },
   "source": [
    "## Deliverables\n",
    "\n",
    "* This file.\n",
    "* A \"checkpoint file\" `\"checkpoint.pth\"` that contains your CNN's weights (you get them from `model.state_dict()`). Obtain it with `torch.save(..., \"checkpoint.pth\")`. When grading, we will load it to evaluate your accuracy.\n",
    "\n",
    "**Should you decide to put your `\"checkpoint.pth\"` on Google Drive, update (edit) the following cell with the link to it:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQCVDqPMaAXR"
   },
   "source": [
    "### [Dear TAs, I've put my \"checkpoint.pth\" on Google Drive, download it here](https://drive.google.com/file/d/1CJ3gseVFd5ma9MBCSFEbtio0Wyvcr25M/view?usp=sharing )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmZdJUu3aAXT"
   },
   "source": [
    "## Grading\n",
    "\n",
    "* 9 points for reproducible training code and a filled report below.\n",
    "* 11 points for building a network that gets above 25% accuracy.\n",
    "* 4 points for using an **interactive** (please don't reinvent the wheel with `plt.plot`) tool for viewing progress, for example Tensorboard ([with this library](https://github.com/lanpa/tensorboardX) and [an extra hack for Colab](https://stackoverflow.com/a/57791702)). In this notebook, insert screenshots of accuracy and loss plots (training and validation) over iterations/epochs/time.\n",
    "* 6 points for beating each of these accuracy milestones on the private **test** set:\n",
    "  * 30%\n",
    "  * 34%\n",
    "  * 38%\n",
    "  * 42%\n",
    "  * 46%\n",
    "  * 50%\n",
    "  \n",
    "*Private test set* means that you won't be able to evaluate your model on it. Rather, after you submit code and checkpoint, we will load your model and evaluate it on that test set ourselves, reporting your accuracy in a comment to the grade.\n",
    "\n",
    "Note that there is an important formatting requirement, see below near \"`DO_TRAIN = True`\".\n",
    "\n",
    "## Restrictions\n",
    "\n",
    "* No pretrained networks.\n",
    "* Don't enlarge images (e.g. don't resize them to $224 \\times 224$ or $256 \\times 256$).\n",
    "\n",
    "## Tips\n",
    "\n",
    "* **One change at a time**: never test several new things at once (unless you are super confident). Train a model, introduce one change, train again.\n",
    "* Google a lot.\n",
    "* Use GPU.\n",
    "* Use regularization: L2, batch normalization, dropout, data augmentation...\n",
    "* Pay much attention to accuracy and loss graphs (e.g. in Tensorboard). Track failures early, stop bad experiments early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1CwN7naVXMe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EfiyBMpaAXW"
   },
   "outputs": [],
   "source": [
    "# Detect if we are in Google Colaboratory\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "from pathlib import Path\n",
    "# Determine the locations of auxiliary libraries and datasets.\n",
    "# `AUX_DATA_ROOT` is where 'notmnist.py', 'animation.py' and 'tiny-imagenet-2020.zip' are.\n",
    "if IN_COLAB:\n",
    "    google.colab.drive.mount(\"/content/drive\")\n",
    "    \n",
    "    # Change this if you created the shortcut in a different location\n",
    "    AUX_DATA_ROOT = Path(\"/content/drive/My Drive/Deep Learning 2020 -- Home Assignment 2\")\n",
    "    \n",
    "    assert AUX_DATA_ROOT.is_dir(), \"Have you forgot to 'Add a shortcut to Drive'?\"\n",
    "else:\n",
    "    AUX_DATA_ROOT = Path(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CC7712Mufhde"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g7UwVMTraAXm"
   },
   "source": [
    "The below cell puts training and validation images in `./tiny-imagenet-200/train` and `./tiny-imagenet-200/val`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCKll06KaAXq"
   },
   "outputs": [],
   "source": [
    "# Extract the dataset into the current directory\n",
    "if not Path(\"tiny-imagenet-200/train/class_000/00000.jpg\").is_file():\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(AUX_DATA_ROOT / 'tiny-imagenet-2020.zip', 'r') as archive:\n",
    "        archive.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0__0o6MmaAX2"
   },
   "source": [
    "**You are required** to format your notebook cells so that `Run All` on a fresh notebook:\n",
    "* trains your model from scratch, if `DO_TRAIN is True`;\n",
    "* loads your trained model from `\"./checkpoint.pth\"`, then **computes** and prints its validation accuracy, if `DO_TRAIN is False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aa_EpTZHaAX4"
   },
   "outputs": [],
   "source": [
    "DO_TRAIN = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFVHa7E4aAYE"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ia-qhrttaAYG"
   },
   "outputs": [],
   "source": [
    "# Your code here (feel free to add cells)\n",
    "import torch as t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision as tv\n",
    "from torchvision import transforms,utils\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as opt\n",
    "from IPython import display\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm_notebook\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bn--wqL1kA4G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uBLxWGDsTHiC"
   },
   "source": [
    "- Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Xs7Nh8gSUZb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7x3b8-W6UQRy"
   },
   "outputs": [],
   "source": [
    "#training transformation...\n",
    "transform_1 = transforms.Compose([\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(hue = 0.05, brightness = 0.2, contrast=0.2),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "#validation transformation..    \n",
    "transform_2 = transforms.Compose([\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "\n",
    "train_set = tv.datasets.ImageFolder('tiny-imagenet-200/train', transform=transform_1)\n",
    "val_set = tv.datasets.ImageFolder('tiny-imagenet-200/val', transform=transform_2)\n",
    "\n",
    "train_dataloader = t.utils.data.DataLoader(train_set, batch_size=200,shuffle=True)\n",
    "val_dataloader =  t.utils.data.DataLoader(val_set, batch_size=200,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csrKkNSxdsQi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G4jK0rghYwAP"
   },
   "outputs": [],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Go6Sm6w5xd-p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V71QcH3SiM2A"
   },
   "outputs": [],
   "source": [
    "class Flatten(t.nn.Module):\n",
    "    def forward(self,input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "model = []\n",
    "####################################################################\n",
    "#1st Convolution layer....\n",
    "model.append(nn.Conv2d(3,64,3,stride=1, padding=1, bias=False))\n",
    "model.append(nn.BatchNorm2d(64))\n",
    "model.append(nn.ReLU(inplace=True))\n",
    "model.append(nn.MaxPool2d(3,padding=1,stride=2))\n",
    "model.append(nn.Dropout(p=0.3))\n",
    "\n",
    "\n",
    "######################################################################\n",
    "#2nd Convolution layer....\n",
    "model.append(nn.Conv2d(64,2*64,3,stride=1,padding=1,bias=False))\n",
    "model.append(nn.BatchNorm2d(2*64))\n",
    "model.append(nn.ReLU(inplace=True))\n",
    "model.append(nn.Dropout(p=0.3))\n",
    "\n",
    "######################################################################\n",
    "#3rd Convolution layer....\n",
    "model.append(nn.Conv2d(2*64,2*64,3,stride=2,padding=1,bias=False))\n",
    "model.append(nn.BatchNorm2d(2*64))\n",
    "model.append(nn.ReLU(inplace=True))\n",
    "model.append(nn.Dropout(p=0.3))\n",
    "\n",
    "######################################################################\n",
    "#4th Convolution layer....\n",
    "model.append(nn.Conv2d(2*64,4*64,3,stride=1,padding=1,bias=False))\n",
    "model.append(nn.BatchNorm2d(4*64))\n",
    "model.append(nn.ReLU(inplace=True))\n",
    "model.append(nn.Dropout(p=0.3))\n",
    "\n",
    "########################################################################\n",
    "#5th Convolution layer....\n",
    "model.append(nn.Conv2d(4*64,4*64,3,stride=2,padding=1,bias=False))\n",
    "model.append(nn.BatchNorm2d(4*64))\n",
    "model.append(nn.ReLU(inplace=True))\n",
    "########################################################################\n",
    "#7th Convolution layer....\n",
    "model.append(nn.Conv2d(4*64,8*64,3,stride=1,padding=1,bias=False))\n",
    "model.append(nn.BatchNorm2d(8*64))\n",
    "model.append(nn.ReLU(inplace=True))\n",
    "model.append(nn.Dropout(p=0.3))\n",
    "\n",
    "#######################################################################\n",
    "model.append(nn.AvgPool2d(3,padding=1, stride = 2))\n",
    "model.append(Flatten())\n",
    "model.append(nn.Linear(128*64,200))\n",
    "model.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "#######################################################################\n",
    "model_net =  nn.Sequential(*model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3500bFpzD0v"
   },
   "outputs": [],
   "source": [
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "model_net = model_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRCz8l-Kqlu_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D5kWNWi4zDtZ"
   },
   "outputs": [],
   "source": [
    "print(model_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNMYYyo4lJ9q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_w6eUZ2VUIwe"
   },
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZN323QF1HvL"
   },
   "outputs": [],
   "source": [
    "criterion = t.nn.CrossEntropyLoss()\n",
    "adam_opt_ = t.optim.Adam(model_net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gWDWLXT0OcUT"
   },
   "outputs": [],
   "source": [
    "def get_acc(model, dataloader, device):\n",
    "    acc_value = 0\n",
    "    with t.no_grad():\n",
    "        for img, label in dataloader:\n",
    "            img = img.to(device)  \n",
    "            label = label.to(device)  \n",
    "            pred = model(img).argmax(dim=-1, keepdim=True)\n",
    "            acc_value += pred.eq(label.view_as(pred)).sum().item()\n",
    "    return acc_value / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cK7kSXqUBDrM"
   },
   "outputs": [],
   "source": [
    "# tv.models.resnet18()\n",
    "# class OwnResnet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.resnet = torchvision.models.resnet18()\n",
    "#         self.resnet.fc = nn.Linear(512, 200)\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         return self.resnet(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EN_zAzNdADuD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "niB98KaiFHNj"
   },
   "outputs": [],
   "source": [
    "def random_seeds(seed_=0, device = 0):\n",
    "    t.cuda.manual_seed(seed_)\n",
    "    t.cuda.manual_seed_all(seed_)\n",
    "    t.backends.cudnn.deterministic = True\n",
    "    t.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbQjKkX1fwIA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jT2ggV1vQUzg"
   },
   "outputs": [],
   "source": [
    "train_len = len(train_set)\n",
    "bs=100\n",
    "n = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zG0qKNWqcOqT"
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6x64xsD4Y_PR"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def model_training(model,opt,scheduler=None,write = True): \n",
    "    #exp_name='my_network'\n",
    "    writer = SummaryWriter()\n",
    "    model.to(device)\n",
    "    criterion = t.nn.CrossEntropyLoss()\n",
    "    val_acc_ = 0\n",
    "    val_acc_n = 0\n",
    "    batches_n = (train_len)//bs\n",
    "    lrc = [np.nan]*n\n",
    "    train_acc_curve = [np.nan]*n\n",
    "    val_acc_curve = [np.nan]*n\n",
    "    \n",
    "    for _ in tqdm_notebook(range(n)):\n",
    "        if scheduler is not None:  \n",
    "            scheduler.step()       \n",
    "        model.train()\n",
    "\n",
    "        lrc[_] = 0\n",
    "        for img,label in train_dataloader:\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            opt.zero_grad()\n",
    "            pred = model(img)\n",
    "            loss_value = criterion(pred,label)\n",
    "            lrc[_] += loss_value.item()\n",
    "            loss_value.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        writer.add_scalar('train loss', loss_value.item(), global_step=len(lrc))\n",
    "        \n",
    "        model.eval()\n",
    "        train_acc_curve[_] = get_acc(model, train_dataloader, device)\n",
    "        val_acc_curve[_] = get_acc(model, val_dataloader, device)\n",
    "        val_accuracy = val_acc_curve[_]\n",
    "        if val_accuracy > val_acc_:\n",
    "            val_acc_ = val_accuracy\n",
    "            val_acc_n = _\n",
    "            if write:\n",
    "                t.save(model.state_dict(),'checkpoint.pth')\n",
    "        writer.add_graph(model, img[:8])\n",
    "        writer.add_scalar('Training accuracy', train_acc_curve[_],_ + 1)\n",
    "        writer.add_scalar('Validation accuracy', val_acc_curve[_], _ + 1)  \n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(lrc, 'b')\n",
    "        plt.xlabel('Number of iteration')\n",
    "        plt.ylabel('Loss value')\n",
    "        plt.title('Learning Curve')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(train_acc_curve, 'r', label ='Training Acccuracy')\n",
    "        plt.plot(val_acc_curve, 'g', label ='Validation Accuracy')\n",
    "        plt.xlabel('Number of iteration')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Display and Training and Validation Accuracies')\n",
    "        plt.legend(loc = 'best')\n",
    "        plt.show()\n",
    "        print(\"Training Loss: \" ,loss_value)\n",
    "        print(\"Training accuracy :%.2f%%\" % (train_acc_curve[_]*100))\n",
    "        print(\"Validation accuracy: %.2f%%\" % (val_accuracy * 100))\n",
    "        print(\"Validation Max_accuracy: %.2f%%\" % (val_acc_ * 100))\n",
    "        print(\"Validation Max_accuracy Epoch: \", val_acc_n)\n",
    "         #val_accuracy, max_val_accuracy, max_val_accuracy_epoch))\n",
    "    \n",
    "\n",
    "random_seeds(device=device)\n",
    "scheduler = t.optim.lr_scheduler.MultiStepLR(adam_opt_, (20, 30), gamma=.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lg6skSVXqMPQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdOPYvPmWvFF"
   },
   "outputs": [],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "logs_base_dir = \"./logs\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tv7oFjLwqa4w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQIxZ4FdaAYQ"
   },
   "outputs": [],
   "source": [
    "if DO_TRAIN:\n",
    "    # Your code here (train your model)\n",
    "    %%time\n",
    "    model_training(model_net,adam_opt_,scheduler=scheduler,write = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDHFO_Vw36hC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mhIhozvsaAYc"
   },
   "source": [
    "## Load and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ItHTy_TlaAYf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your code here (load the model from \"./checkpoint.pth\")\n",
    "# Please use `torch.load(\"checkpoint.pth\", map_location='cpu')`\n",
    "if not DO_TRAIN:\n",
    "  model_net.load_state_dict(t.load('checkpoint.pth',map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hC9I_2VXaAYs"
   },
   "outputs": [],
   "source": [
    "val_accuracy =  get_acc(model_net,val_dataloader, device) * 100\n",
    "# Your code here\n",
    "assert 0 <= val_accuracy <= 100\n",
    "print(\"Validation accuracy: %.2f%%\" % val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CyC-P_JZdO9c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RiFJyXHTaAY2"
   },
   "source": [
    "# Report\n",
    "\n",
    "Below, please mention:\n",
    "\n",
    "* A brief history of tweaks and improvements.\n",
    "* Which network architectures have you tried? What is the final one and why?\n",
    "* What is the training method (batch size, optimization algorithm, number of iterations, ...) and why?\n",
    "* Which techniques have you tried to prevent overfitting? What were their effects? Which of them worked well?\n",
    "* Any other insights you learned.\n",
    "\n",
    "For example, start with:\n",
    "\n",
    "\"I have analyzed these and those conference papers/sources/blog posts. \\\n",
    "I tried this and that to adapt them to my problem. \\\n",
    "The conclusions this task taught me are ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFLWojgIstgj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YqkdYsXoXG4r"
   },
   "source": [
    "- Starting off by studying the [Tiny ImageNet Challenge](http://cs231n.stanford.edu/reports/2017/pdfs/935.pdf) paper by Yinbin Ma of Standford University, the initial approcah to solving this problem is by implementing ResNet_18.\n",
    "\n",
    "- By applying  the Resnet-18 without pretrained weights, I applied this directly to the ImageNet,and a val_accuracy of 30.9% was achieved.However, In getting a drastic improvement on this, the parameters has to be altered within the layers layout.\n",
    "\n",
    "- I resolved to building a Neural Network architecture from scratch using  ideas from Con2d-model in seminar -3 coulped with data augumentation.\n",
    "\n",
    "- The tranformtion that was done on the data was mainly to achieve a better accuracy through data augumentation, I applied some rotation, as well as color transformation on the data.\n",
    "\n",
    "- My model consist of a simple Convolutional Neural Network with \"Relu\" as my activation in all layers. Relu seems to be a more effective activation function as I saw from HW1. I added BatchNorm to achieve as much accuracy as possible with lesser training steps. I used 7- Conv2d() layers and I wrapped this  up with  a linear layer. For the output layer, I used  LogSoftMax, and I used cross entropy loss as my loss metric.\n",
    "\n",
    "- To avoid overfitting , I added a dropout layer after every Relu activation function.\n",
    "\n",
    "- Training was done with batch-size of 100, epoch of 30, learning rate is 1e-3 and optmization by AdamOptimizer was used. AdamOptimizer has proven to be better than SGD from previous task.\n",
    "\n",
    "- in my training procedure, I also made a point out of the max_validation accuracy at every iteration and the epoch at which this max accuracy occurs.\n",
    "Tgis help to show me teh point at which drop in the validation accuracy occurs for several raining trials\n",
    "\n",
    "- For me, working on this model from scratch and combined with knowledge garnered from seminars, it gives me a better undertadning on training methods, patterns and approach in getting the better result at every level.\n",
    "\n",
    "- I was able to obtain a training accuracy of = 79.51%, and a validation accuracy of 48.60% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "df6MzrScem4D"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Submit_hw2_Oluwafemi_Olaleke_Part 2.ipynb",
   "provenance": [
    {
     "file_id": "1BL8Eqo13RfKkveEXuuooCL7Od-MKEWgu",
     "timestamp": 1588171240932
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
